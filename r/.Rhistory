independent["percentobesity2004"] <- lapply(independent["percentobesity2004"], as.numeric)
independent["ageadjustedpercentobesity2004"] <- lapply(independent["ageadjustedpercentobesity2004"], as.numeric)
independent["numberleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["numberleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["percentleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["percentleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["ageadjustedpercentleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["ageadjustedpercentleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["HHNV1MI"] <- lapply(independent["HHNV1MI"], as.numeric)
independent["FFRPTH07"] <- lapply(independent["FFRPTH07"], as.numeric)
independent["FSRPTH07"] <- lapply(independent["FSRPTH07"], as.numeric)
independent["PH_FRUVEG"] <- lapply(independent["PH_FRUVEG"], as.numeric)
independent["PH_SNACKS"] <- lapply(independent["PH_SNACKS"], as.numeric)
independent["PH_SODA"] <- lapply(independent["PH_SODA"], as.numeric)
independent["PH_MEAT"] <- lapply(independent["PH_MEAT"], as.numeric)
independent["PH_FATS"] <- lapply(independent["PH_FATS"], as.numeric)
independent["PH_PREPFOOD"] <- lapply(independent["PH_PREPFOOD"], as.numeric)
independent["medicare"] <- lapply(independent["medicare"], as.numeric)
# Remove na
independent = independent[complete.cases(independent),]
# convert to numeric
dependentQuintiles["ageadjustedrate"] <- lapply(dependentQuintiles["ageadjustedrate"], as.numeric)
# Remove ' County' substring from County field
dependentQuintiles["County"] <- lapply(dependentQuintiles["County"], gsub, pattern = " County", replacement = "", fixed = TRUE)
# Join independent with dependent quintiles
merged <- merge(x=independent, y=dependentQuintiles, by.x="Areaname", by.y=gsub(" County", "", "County"))
# Remove na, null
merged = merged[complete.cases(merged),]
merged <- merged[merged$Quintiles!="#NULL!",]
merged <- convert_vector_of_columns_to_binary(merged, c("educationHighSchoolOrAboveRate",
"ageadjustedpercentleisuretimephysicalinactivityprevalence2004",
"percentleisuretimephysicalinactivityprevalence2004",
"perCapitaIncome",
"medianHouseholdIncome2000",
"peopleInPovertyRate",
"ageadjustedpercentobesity2004",
"perCapitaPersonalIncome",
"percentobesity2004",
"sampleMedianHousingUnitValue",
"AvgDailyMaxAirTemperatureF",
"AvgDailyMinAirTemperatureF",
"AvgDailyMaxHeatIndexF",
"unemploymentRate",
"AvgDayLandSurfaceTemperatureF",
"AvgDailyPrecipitationmm",
"AvgFineParticulateMatterÂµgm",
"populationPerSquareMile",
"percent2004diabetes",
"populationMedianAgeApril2000",
"ageadjustedpercent2004diabetes"))
append_ntile_column <- function(df, column, n) {
df <- within(df, new_quintile <- as.integer(cut(df[,column], quantile(df[,column], probs=0:n/n), include.lowest=TRUE)))
new_col_name <- paste0(n, "tile.", column)
names(df)[ncol(df)] <- new_col_name
return(df)
}
append_quintile_column <- function(df, column) {
return(append_ntile_column(df, column, 5))
}
convert_ntile_to_binary <- function(df, column, n) {
for (i in 1:n) {
df <- within(df, new_col <- as.integer(ifelse(df[column] == i, 1, 0)))
new_col_name <- paste0(column, ".", i)
names(df)[ncol(df)] <- new_col_name
}
return(df)
}
convert_quintile_to_binary <- function(df, column) {
return(convert_ntile_to_binary(df, column, 5))
}
convert_vector_of_columns_to_binary <- function(df, columns) {
for (column in columns) {
df <- append_quintile_column(df, column)
colname <- paste0("5tile.", column)
df <- convert_quintile_to_binary(df, colname)
}
return(df)
}
merged <- convert_vector_of_columns_to_binary(merged, c("educationHighSchoolOrAboveRate",
"ageadjustedpercentleisuretimephysicalinactivityprevalence2004",
"percentleisuretimephysicalinactivityprevalence2004",
"perCapitaIncome",
"medianHouseholdIncome2000",
"peopleInPovertyRate",
"ageadjustedpercentobesity2004",
"perCapitaPersonalIncome",
"percentobesity2004",
"sampleMedianHousingUnitValue",
"AvgDailyMaxAirTemperatureF",
"AvgDailyMinAirTemperatureF",
"AvgDailyMaxHeatIndexF",
"unemploymentRate",
"AvgDayLandSurfaceTemperatureF",
"AvgDailyPrecipitationmm",
"AvgFineParticulateMatterÂµgm",
"populationPerSquareMile",
"percent2004diabetes",
"populationMedianAgeApril2000",
"ageadjustedpercent2004diabetes"))
dataset <- merged[,c("5tile.educationHighSchoolOrAboveRate",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004",
"5tile.percentleisuretimephysicalinactivityprevalence2004",
"5tile.perCapitaIncome",
"5tile.medianHouseholdIncome2000",
"5tile.peopleInPovertyRate",
"5tile.ageadjustedpercentobesity2004",
"5tile.perCapitaPersonalIncome",
"5tile.percentobesity2004",
"5tile.sampleMedianHousingUnitValue",
"5tile.AvgDailyMaxAirTemperatureF",
"5tile.AvgDailyMinAirTemperatureF",
"5tile.AvgDailyMaxHeatIndexF",
"5tile.unemploymentRate",
"5tile.AvgDayLandSurfaceTemperatureF",
"5tile.AvgDailyPrecipitationmm",
"5tile.AvgFineParticulateMatterÂµgm",
"5tile.populationPerSquareMile",
"5tile.percent2004diabetes",
"5tile.populationMedianAgeApril2000",
"5tile.ageadjustedpercent2004diabetes",
"Quintiles")]
################################################################################
# 4. prepare for decision tree modeling
# Build the training/validate/test datasets.
# set seed to ensure reproducible results
set.seed(42)
# split into training and test sets
dataset[,"train"] <- ifelse(runif(nrow(dataset))<0.8,1,0)
# separate training and test sets
trainset <- dataset[dataset$train == 1,]
testset <- dataset[dataset$train == 0,]
# get column index of train flag
trainColNum <- grep("train", names(trainset))
# remove train flag column
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]
# get column index of predicted variable
typeColNum <- grep("Quintiles", names(dataset))
################################################################################
# 5. build decision trees
# build model
rpart_model <- rpart(Quintiles ~ ., data = trainset, method = "class")
# plot tree
rpart.plot(rpart_model)
# try against test data
rpart_predict <- predict(rpart_model, testset[, -typeColNum], type = "class")
mean(rpart_predict == testset$Quintiles)
# confusion matrix
table(pred = rpart_predict, true = testset$Quintiles)
# cost-complexity pruning
# pick the appropriate pruning parameter alpha by
# picking the value that results in the lowest prediction error
# alpha = CP
# cross-val error = xerror
printcp(rpart_model)
# get index of CP with lowest xerror
opt <- which.min(rpart_model$cptable[, "xerror"])
# get its value
cp <- rpart_model$cptable[opt, "CP"]
# prune the tree based on cp
pruned_model <- prune(rpart_model, cp)
# plot
rpart.plot(pruned_model)
# find proportion of correct predictions using test set
rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
mean(rpart_pruned_predict == testset$Quintiles)
# function to do multiple runs
multiple_runs_classification <- function(train_fraction, n, dataset, prune_tree = FALSE) {
fraction_correct <- rep(NA, n)
set.seed(42)
for (i in 1:n) {
dataset[, "train"] <- ifelse(runif(nrow(dataset)) < 0.8, 1, 0)
trainColNum <- grep("train", names(dataset))
typeColNum <- grep("Quintiles", names(dataset))
trainset <- dataset[dataset$train == 1, -trainColNum]
testset <- dataset[dataset$train == 0, -trainColNum]
rpart_model <- rpart(Quintiles ~ ., data = trainset, method = "class")
if (prune_tree == FALSE) {
rpart_test_predict <- predict(rpart_model, testset[, -typeColNum], type = "class")
fraction_correct[i] <- mean(rpart_test_predict == testset$Quintiles)
} else {
opt <- which.min(rpart_model$cptable[, "xerror"])
cp <- rpart_model$cptable[opt, "CP"]
pruned_model <- prune(rpart_model, cp)
rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
fraction_correct[i] <- mean(rpart_pruned_predict == testset$Quintiles)
}
}
return(fraction_correct)
}
# 50 runs without pruning
unpruned_set <- multiple_runs_classification(0.8, 50, dataset)
mean(unpruned_set)
sd(unpruned_set)
# 50 runs with pruning
pruned_set <- multiple_runs_classification(0.8, 50, dataset, prune_tree = TRUE)
mean(pruned_set)
sd(pruned_set)
library(rpart)
library(rpart.plot)
################################################################################
# 4. prepare for decision tree modeling
# Build the training/validate/test datasets.
# set seed to ensure reproducible results
set.seed(42)
# split into training and test sets
dataset[,"train"] <- ifelse(runif(nrow(dataset))<0.8,1,0)
# separate training and test sets
trainset <- dataset[dataset$train == 1,]
testset <- dataset[dataset$train == 0,]
# get column index of train flag
trainColNum <- grep("train", names(trainset))
# remove train flag column
trainset <- trainset[,-trainColNum]
testset <- testset[,-trainColNum]
# get column index of predicted variable
typeColNum <- grep("Quintiles", names(dataset))
################################################################################
# 5. build decision trees
# build model
rpart_model <- rpart(Quintiles ~ ., data = trainset, method = "class")
# plot tree
rpart.plot(rpart_model)
# try against test data
rpart_predict <- predict(rpart_model, testset[, -typeColNum], type = "class")
mean(rpart_predict == testset$Quintiles)
# confusion matrix
table(pred = rpart_predict, true = testset$Quintiles)
# cost-complexity pruning
# pick the appropriate pruning parameter alpha by
# picking the value that results in the lowest prediction error
# alpha = CP
# cross-val error = xerror
printcp(rpart_model)
# get index of CP with lowest xerror
opt <- which.min(rpart_model$cptable[, "xerror"])
# get its value
cp <- rpart_model$cptable[opt, "CP"]
# prune the tree based on cp
pruned_model <- prune(rpart_model, cp)
# plot
rpart.plot(pruned_model)
# find proportion of correct predictions using test set
rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
mean(rpart_pruned_predict == testset$Quintiles)
# function to do multiple runs
multiple_runs_classification <- function(train_fraction, n, dataset, prune_tree = FALSE) {
fraction_correct <- rep(NA, n)
set.seed(42)
for (i in 1:n) {
dataset[, "train"] <- ifelse(runif(nrow(dataset)) < 0.8, 1, 0)
trainColNum <- grep("train", names(dataset))
typeColNum <- grep("Quintiles", names(dataset))
trainset <- dataset[dataset$train == 1, -trainColNum]
testset <- dataset[dataset$train == 0, -trainColNum]
rpart_model <- rpart(Quintiles ~ ., data = trainset, method = "class")
if (prune_tree == FALSE) {
rpart_test_predict <- predict(rpart_model, testset[, -typeColNum], type = "class")
fraction_correct[i] <- mean(rpart_test_predict == testset$Quintiles)
} else {
opt <- which.min(rpart_model$cptable[, "xerror"])
cp <- rpart_model$cptable[opt, "CP"]
pruned_model <- prune(rpart_model, cp)
rpart_pruned_predict <- predict(pruned_model, testset[, -typeColNum], type = "class")
fraction_correct[i] <- mean(rpart_pruned_predict == testset$Quintiles)
}
}
return(fraction_correct)
}
# 50 runs without pruning
unpruned_set <- multiple_runs_classification(0.8, 50, dataset)
mean(unpruned_set)
sd(unpruned_set)
# 50 runs with pruning
pruned_set <- multiple_runs_classification(0.8, 50, dataset, prune_tree = TRUE)
mean(pruned_set)
sd(pruned_set)
dataset
dataset <- convert_quintile_to_binary(dataset, "Quintiles")
if(!require("installr")) install.packages('installr')
library("installr")
updateR()
tmp = installed.packages()
installedpackages = as.vector(tmp[is.na(tmp[,"Priority"]), 1])
save(installedpackages, file="c:\\jsorbo\\installed_packages.rda")
View(dataset)
View(dataset2)
trans = read.transactions(filename, format="basket", sep=",")
library(arules)
filename <- "c:\\jsorbo\\repos\\msseproject\\exposome-data\\arulesdata.csv"
write.csv(arulesdataset, file=filename)
trans = read.transactions(filename, format="basket", sep=",")
View(merged)
library(rpart)
library(rpart.plot)
################################################################################
# 2. load data, rename columns, clean data, merge data frames
# Import from csv
independent <- read.csv(file="..\\exposome-data\\independent.csv", header=TRUE)
dependentQuintiles <- read.csv(file="..\\exposome-data\\dependentQuintiles.csv", header=TRUE)
renameColumn <- function(dataFrame, from, to) {
names(dataFrame)[names(dataFrame) == from] <- to
return(dataFrame)
}
independent <- renameColumn(independent, "AGE030200D", "populationApril2000")
independent <- renameColumn(independent, "AGE040200D", "populationJuly2000")
independent <- renameColumn(independent, "AGE050200D", "populationMedianAgeApril2000")
independent <- renameColumn(independent, "BNK010200D", "bankOfficesJune2000")
independent <- renameColumn(independent, "BNK050200D", "bankDepositsJune2000")
independent <- renameColumn(independent, "CLF030200D", "unemployment")
independent <- renameColumn(independent, "CLF040200D", "unemploymentRate")
independent <- renameColumn(independent, "CRM110200D", "violentCrimes")
independent <- renameColumn(independent, "EDU635200D", "educationHighSchoolOrAboveRate")
independent <- renameColumn(independent, "HEA010200D", "insuranceOrMedicare")
independent <- renameColumn(independent, "HEA070200D", "medicare")
independent <- renameColumn(independent, "HSD150200D", "householdsMaleNoWife")
independent <- renameColumn(independent, "HSD170200D", "householdsFemaleNoHusband")
independent <- renameColumn(independent, "HSG455200D", "ownerOccupiedHomesHouseholderBlackOrAfricanAmerican")
independent <- renameColumn(independent, "HSG460200D", "ownerOccupiedHomesHouseholderHispanicOrLatino")
independent <- renameColumn(independent, "HSG495200D", "sampleMedianHousingUnitValue")
independent <- renameColumn(independent, "HSG680200D", "renterOccupiedHousingUnits")
independent <- renameColumn(independent, "HSG695200D", "renterOccupiedHomesHouseholderBlackOrAfricanAmerican")
independent <- renameColumn(independent, "HSG700200D", "renterOccupiedHomesHouseholderHispanicOrLatino")
independent <- renameColumn(independent, "INC110199D", "medianHouseholdIncome1999")
independent <- renameColumn(independent, "INC415199D", "meanHouseholdEarnings")
independent <- renameColumn(independent, "INC420200D", "householdsWithSocialSecurityIncome")
independent <- renameColumn(independent, "INC910199D", "perCapitaIncome")
independent <- renameColumn(independent, "IPE010200D", "medianHouseholdIncome2000")
independent <- renameColumn(independent, "IPE120200D", "peopleInPovertyRate")
independent <- renameColumn(independent, "LND110200D", "landArea")
independent <- renameColumn(independent, "PIN020200D", "perCapitaPersonalIncome")
independent <- renameColumn(independent, "POP060200D", "populationPerSquareMile")
independent <- renameColumn(independent, "POP110200D", "urbanPopulationSample")
independent <- renameColumn(independent, "POP150200D", "malePopulationCompleteCount")
independent <- renameColumn(independent, "POP160200D", "femalePopulationCompleteCount")
independent <- renameColumn(independent, "POP220200D", "populationOfOneRaceWhiteAloneCompleteCount")
independent <- renameColumn(independent, "POP250200D", "populationOfOneRaceBlackOrAfricanAmericanAloneCompleteCount")
independent <- renameColumn(independent, "PVY020199D", "populationBelowPovertyLevel")
independent <- renameColumn(independent, "SPR010200D", "socialSecurityBenefitRecipients")
independent <- renameColumn(independent, "SPR410200D", "supplementalSecurityIncomeRecipients")
# Convert to numeric
independent["medianHouseholdIncome2000"] <- lapply(independent["medianHouseholdIncome2000"], as.numeric)
independent["peopleInPovertyRate"] <- lapply(independent["peopleInPovertyRate"], as.numeric)
independent["insuranceOrMedicare"] <- lapply(independent["insuranceOrMedicare"], as.numeric)
independent["violentCrimes"] <- lapply(independent["violentCrimes"], as.numeric)
independent["perCapitaPersonalIncome"] <- lapply(independent["perCapitaPersonalIncome"], as.numeric)
independent["educationHighSchoolOrAboveRate"] <- lapply(independent["educationHighSchoolOrAboveRate"], as.numeric)
independent["populationPerSquareMile"] <- lapply(independent["populationPerSquareMile"], as.numeric)
independent["urbanPopulationSample"] <- lapply(independent["urbanPopulationSample"], as.numeric)
independent["malePopulationCompleteCount"] <- lapply(independent["malePopulationCompleteCount"], as.numeric)
independent["femalePopulationCompleteCount"] <- lapply(independent["femalePopulationCompleteCount"], as.numeric)
independent["populationOfOneRaceWhiteAloneCompleteCount"] <- lapply(independent["populationOfOneRaceWhiteAloneCompleteCount"], as.numeric)
independent["populationOfOneRaceBlackOrAfricanAmericanAloneCompleteCount"] <- lapply(independent["populationOfOneRaceBlackOrAfricanAmericanAloneCompleteCount"], as.numeric)
independent["renterOccupiedHousingUnits"] <- lapply(independent["renterOccupiedHousingUnits"], as.numeric)
independent["renterOccupiedHomesHouseholderBlackOrAfricanAmerican"] <- lapply(independent["renterOccupiedHomesHouseholderBlackOrAfricanAmerican"], as.numeric)
independent["renterOccupiedHomesHouseholderHispanicOrLatino"] <- lapply(independent["renterOccupiedHomesHouseholderHispanicOrLatino"], as.numeric)
independent["householdsMaleNoWife"] <- lapply(independent["householdsMaleNoWife"], as.numeric)
independent["householdsFemaleNoHusband"] <- lapply(independent["householdsFemaleNoHusband"], as.numeric)
independent["socialSecurityBenefitRecipients"] <- lapply(independent["socialSecurityBenefitRecipients"], as.numeric)
independent["supplementalSecurityIncomeRecipients"] <- lapply(independent["supplementalSecurityIncomeRecipients"], as.numeric)
independent["landArea"] <- lapply(independent["landArea"], as.numeric)
independent["unemploymentRate"] <- lapply(independent["unemploymentRate"], as.numeric)
independent["bankOfficesJune2000"] <- lapply(independent["bankOfficesJune2000"], as.numeric)
independent["AvgFineParticulateMatterÂµgm"] <- lapply(independent["AvgFineParticulateMatterÂµgm"], as.numeric)
independent["AvgDailyPrecipitationmm"] <- lapply(independent["AvgDailyPrecipitationmm"], as.numeric)
independent["AvgDayLandSurfaceTemperatureF"] <- lapply(independent["AvgDayLandSurfaceTemperatureF"], as.numeric)
independent["AvgDailyMaxAirTemperatureF"] <- lapply(independent["AvgDailyMaxAirTemperatureF"], as.numeric)
independent["AvgDailyMinAirTemperatureF"] <- lapply(independent["AvgDailyMinAirTemperatureF"], as.numeric)
independent["AvgDailyMaxHeatIndexF"] <- lapply(independent["AvgDailyMaxHeatIndexF"], as.numeric)
independent["populationApril2000"] <- lapply(independent["populationApril2000"], as.numeric)
independent["populationJuly2000"] <- lapply(independent["populationJuly2000"], as.numeric)
independent["b_1996"] <- lapply(independent["b_1996"], as.numeric)
independent["b_1997"] <- lapply(independent["b_1997"], as.numeric)
independent["b_1998"] <- lapply(independent["b_1998"], as.numeric)
independent["b_1999"] <- lapply(independent["b_1999"], as.numeric)
independent["b_2000"] <- lapply(independent["b_2000"], as.numeric)
independent["averagesmoke1996to2000"] <- lapply(independent["averagesmoke1996to2000"], as.numeric)
independent["populationMedianAgeApril2000"] <- lapply(independent["populationMedianAgeApril2000"], as.numeric)
independent["number2004diabetes"] <- lapply(independent["number2004diabetes"], as.numeric)
independent["percent2004diabetes"] <- lapply(independent["percent2004diabetes"], as.numeric)
independent["ageadjustedpercent2004diabetes"] <- lapply(independent["ageadjustedpercent2004diabetes"], as.numeric)
independent["ownerOccupiedHomesHouseholderBlackOrAfricanAmerican"] <- lapply(independent["ownerOccupiedHomesHouseholderBlackOrAfricanAmerican"], as.numeric)
independent["ownerOccupiedHomesHouseholderHispanicOrLatino"] <- lapply(independent["ownerOccupiedHomesHouseholderHispanicOrLatino"], as.numeric)
independent["sampleMedianHousingUnitValue"] <- lapply(independent["sampleMedianHousingUnitValue"], as.numeric)
independent["perCapitaIncome"] <- lapply(independent["perCapitaIncome"], as.numeric)
independent["numberobesityprevalence2004"] <- lapply(independent["numberobesityprevalence2004"], as.numeric)
independent["percentobesity2004"] <- lapply(independent["percentobesity2004"], as.numeric)
independent["ageadjustedpercentobesity2004"] <- lapply(independent["ageadjustedpercentobesity2004"], as.numeric)
independent["numberleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["numberleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["percentleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["percentleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["ageadjustedpercentleisuretimephysicalinactivityprevalence2004"] <- lapply(independent["ageadjustedpercentleisuretimephysicalinactivityprevalence2004"], as.numeric)
independent["HHNV1MI"] <- lapply(independent["HHNV1MI"], as.numeric)
independent["FFRPTH07"] <- lapply(independent["FFRPTH07"], as.numeric)
independent["FSRPTH07"] <- lapply(independent["FSRPTH07"], as.numeric)
independent["PH_FRUVEG"] <- lapply(independent["PH_FRUVEG"], as.numeric)
independent["PH_SNACKS"] <- lapply(independent["PH_SNACKS"], as.numeric)
independent["PH_SODA"] <- lapply(independent["PH_SODA"], as.numeric)
independent["PH_MEAT"] <- lapply(independent["PH_MEAT"], as.numeric)
independent["PH_FATS"] <- lapply(independent["PH_FATS"], as.numeric)
independent["PH_PREPFOOD"] <- lapply(independent["PH_PREPFOOD"], as.numeric)
independent["medicare"] <- lapply(independent["medicare"], as.numeric)
# Remove na
independent = independent[complete.cases(independent),]
# convert to numeric
dependentQuintiles["ageadjustedrate"] <- lapply(dependentQuintiles["ageadjustedrate"], as.numeric)
# Remove ' County' substring from County field
dependentQuintiles["County"] <- lapply(dependentQuintiles["County"], gsub, pattern = " County", replacement = "", fixed = TRUE)
# Join independent with dependent quintiles
merged <- merge(x=independent, y=dependentQuintiles, by.x="Areaname", by.y=gsub(" County", "", "County"))
# Remove na, null
merged = merged[complete.cases(merged),]
merged <- merged[merged$Quintiles!="#NULL!",]
dataset <- merged[,c("5tile.b_1999", "5tile.b_2000", "5tile.averagesmoke1996to2000", "5tile.percent2004diabetes",
"5tile.ageadjustedpercent2004diabetes", "5tile.percentobesity2004", "5tile.ageadjustedpercentobesity2004",
"5tile.percentleisuretimephysicalinactivityprevalence2004",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004", "5tile.PH_SODA", "Quintiles")]
dataset <- merged[,c("b_1999", "b_2000", "averagesmoke1996to2000", "percent2004diabetes",
"ageadjustedpercent2004diabetes", "percentobesity2004", "ageadjustedpercentobesity2004",
"percentleisuretimephysicalinactivityprevalence2004",
"ageadjustedpercentleisuretimephysicalinactivityprevalence2004", "PH_SODA", "Quintiles")]
append_ntile_column <- function(df, column, n) {
df <- within(df, new_quintile <- as.integer(cut(df[,column], quantile(df[,column], probs=0:n/n), include.lowest=TRUE)))
new_col_name <- paste0(n, "tile.", column)
names(df)[ncol(df)] <- new_col_name
return(df)
}
append_quintile_column <- function(df, column) {
return(append_ntile_column(df, column, 5))
}
convert_ntile_to_binary <- function(df, column, n) {
for (i in 1:n) {
df <- within(df, new_col <- as.integer(ifelse(df[column] == i, 1, 0)))
new_col_name <- paste0(column, ".", i)
names(df)[ncol(df)] <- new_col_name
}
return(df)
}
convert_quintile_to_binary <- function(df, column) {
return(convert_ntile_to_binary(df, column, 5))
}
convert_vector_of_columns_to_binary <- function(df, columns) {
for (column in columns) {
df <- append_quintile_column(df, column)
colname <- paste0("5tile.", column)
df <- convert_quintile_to_binary(df, colname)
}
return(df)
}
merged <- convert_vector_of_columns_to_binary(merged, c("b_1999", "b_2000", "averagesmoke1996to2000", "percent2004diabetes",
"ageadjustedpercent2004diabetes", "percentobesity2004", "ageadjustedpercentobesity2004",
"percentleisuretimephysicalinactivityprevalence2004",
"ageadjustedpercentleisuretimephysicalinactivityprevalence2004", "PH_SODA"))
arulesdataset <- convert_quintile_to_binary(merged, "Quintiles")
arulesdataset <- arulesdataset[,c("5tile.b_1999.1",
"5tile.b_1999.2",
"5tile.b_1999.3",
"5tile.b_1999.4",
"5tile.b_1999.5",
"5tile.b_2000.1",
"5tile.b_2000.2",
"5tile.b_2000.3",
"5tile.b_2000.4",
"5tile.b_2000.5",
"5tile.averagesmoke1996to2000.1",
"5tile.averagesmoke1996to2000.2",
"5tile.averagesmoke1996to2000.3",
"5tile.averagesmoke1996to2000.4",
"5tile.averagesmoke1996to2000.5",
"5tile.percent2004diabetes.1",
"5tile.percent2004diabetes.2",
"5tile.percent2004diabetes.3",
"5tile.percent2004diabetes.4",
"5tile.percent2004diabetes.5",
"5tile.ageadjustedpercent2004diabetes.1",
"5tile.ageadjustedpercent2004diabetes.2",
"5tile.ageadjustedpercent2004diabetes.3",
"5tile.ageadjustedpercent2004diabetes.4",
"5tile.ageadjustedpercent2004diabetes.5",
"5tile.percentobesity2004.1",
"5tile.percentobesity2004.2",
"5tile.percentobesity2004.3",
"5tile.percentobesity2004.4",
"5tile.percentobesity2004.5",
"5tile.ageadjustedpercentobesity2004.1",
"5tile.ageadjustedpercentobesity2004.2",
"5tile.ageadjustedpercentobesity2004.3",
"5tile.ageadjustedpercentobesity2004.4",
"5tile.ageadjustedpercentobesity2004.5",
"5tile.percentleisuretimephysicalinactivityprevalence2004.1",
"5tile.percentleisuretimephysicalinactivityprevalence2004.2",
"5tile.percentleisuretimephysicalinactivityprevalence2004.3",
"5tile.percentleisuretimephysicalinactivityprevalence2004.4",
"5tile.percentleisuretimephysicalinactivityprevalence2004.5",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004.1",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004.2",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004.3",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004.4",
"5tile.ageadjustedpercentleisuretimephysicalinactivityprevalence2004.5",
"5tile.PH_SODA.1",
"5tile.PH_SODA.2",
"5tile.PH_SODA.3",
"5tile.PH_SODA.4",
"5tile.PH_SODA.5",
"Quintiles.1",
"Quintiles.2",
"Quintiles.3",
"Quintiles.4",
"Quintiles.5")]
library(arules)
filename <- "c:\\jsorbo\\repos\\msseproject\\exposome-data\\arulesdata.csv"
write.csv(arulesdataset, file=filename)
trans = read.transactions(filename, format="basket", sep=",")
trans
help(trans)
attributes(trans)
